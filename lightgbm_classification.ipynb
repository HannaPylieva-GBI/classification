{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HannaPylieva-GBI/classification/blob/main/lightgbm_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD6wW942wWc4",
        "outputId": "6d2a1ad4-0e90-4fb0-c9a1-373fbffdc08a"
      },
      "id": "JD6wW942wWc4",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow_text) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.51.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (15.0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (63.4.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (23.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.31.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.11.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.19.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (23.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.27.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.2.2)\n",
            "Installing collected packages: tensorflow_text\n",
            "Successfully installed tensorflow_text-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a3fa6072-660d-4773-af6e-5d8ced894002",
      "metadata": {
        "id": "a3fa6072-660d-4773-af6e-5d8ced894002"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text\n",
        "import lightgbm as lgbm\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tqdm import tqdm #progress bar\n",
        "\n",
        "# from spellchecker import SpellChecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "97a36d8e-f5a0-4ae1-82a1-30eaa7d0d2a1",
      "metadata": {
        "id": "97a36d8e-f5a0-4ae1-82a1-30eaa7d0d2a1"
      },
      "outputs": [],
      "source": [
        "train_path = 'gs://gbi_ml/classification_hackathon/bbby_train_new.csv'\n",
        "test_path = 'gs://gbi_ml/classification_hackathon/bbby_test_new.csv'\n",
        "# train_path = 'gs://gbi_ml/classification_hackathon/bbby_train_30_tokenization.pkl'\n",
        "# test_path = 'gs://gbi_ml/classification_hackathon/bbby_test_tokenization.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gcsfs"
      ],
      "metadata": {
        "id": "UQc5wWoiEzqU"
      },
      "id": "UQc5wWoiEzqU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login"
      ],
      "metadata": {
        "id": "8XfMdiO8HCMa"
      },
      "id": "8XfMdiO8HCMa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project 'groupby-development'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJefLCFnHIzg",
        "outputId": "bab397f3-e8c1-4a6d-a6eb-856c192558b4"
      },
      "id": "NJefLCFnHIzg",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "rzXgESUDHneg"
      },
      "id": "rzXgESUDHneg",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "55a00bed-2b5e-4a18-8565-42d7c0a8acfa",
      "metadata": {
        "id": "55a00bed-2b5e-4a18-8565-42d7c0a8acfa"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(train_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "41016920-88c4-4417-ba5a-dde1477a0bd3",
      "metadata": {
        "id": "41016920-88c4-4417-ba5a-dde1477a0bd3"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6931dc19-eae1-4be6-9550-e051f070cac9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6931dc19-eae1-4be6-9550-e051f070cac9",
        "outputId": "0a6e016e-690b-41ab-a103-da074621c539"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((308284, 12), (19481, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KihZezl-wqwQ",
        "outputId": "dcaec15e-e602-443d-a849-994cda1ed7ac"
      },
      "id": "KihZezl-wqwQ",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['bucket_id', 'external_id', 'customer_id', 'bucket_name', 'product_id',\n",
              "       'product_name', 'description', 'image_url', 'len_desc', 'len_name',\n",
              "       'raw_product_name', 'raw_product_description'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cats = sorted(df.bucket_name.unique())\n",
        "id2label = {id_:name_ for id_, name_ in enumerate(cats)}\n",
        "label2id = {name_: id_ for id_, name_ in enumerate(cats)}"
      ],
      "metadata": {
        "id": "b1kPXoRCRLp7"
      },
      "id": "b1kPXoRCRLp7",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "  \n",
        "def def_value():\n",
        "    return -1\n",
        "      \n",
        "# Defining the dict\n",
        "d = defaultdict(int, label2id)"
      ],
      "metadata": {
        "id": "Hbo4TDSqRIdG"
      },
      "id": "Hbo4TDSqRIdG",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df.bucket_name.apply(lambda x: label2id[x])\n",
        "test_df['label'] = test_df['Manual Classification Bucket'].apply(lambda x: d[x])"
      ],
      "metadata": {
        "id": "OyFoPOecRRLI"
      },
      "id": "OyFoPOecRRLI",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n"
      ],
      "metadata": {
        "id": "IQkw0bwivtku"
      },
      "id": "IQkw0bwivtku",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SENTENCES EMBEDDING\n",
        "\n",
        "# Load encoder from Tensorflow for LGBM model\n",
        "use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
        "\n",
        "# Embed sentences for the training set\n",
        "X_train = []\n",
        "for r in tqdm(df.raw_product_description.values):\n",
        "  emb = use(r)\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_train.append(review_emb)\n",
        "\n",
        "X_train = np.array(X_train)\n"
      ],
      "metadata": {
        "id": "bk-GTBAZvcEJ"
      },
      "id": "bk-GTBAZvcEJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df.label.values\n",
        "\n",
        "# Embed sentences for the validation set\n",
        "Val_test = []\n",
        "for r in tqdm(test_df.raw_product_description.values):\n",
        "  emb = use(r)\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  Val_test.append(review_emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zme0CHhQ7Pg",
        "outputId": "ce56beac-84bd-4848-a7a7-03f971f5dc1d"
      },
      "id": "9Zme0CHhQ7Pg",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19481/19481 [08:23<00:00, 38.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gcsfs\n",
        "import pickle \n",
        "\n",
        "base_dir = 'gbi_ml/classification_hackathon/'\n",
        "fs = gcsfs.GCSFileSystem()\n",
        "\n",
        "with fs.open(base_dir+'X_train.pickle', 'wb') as handle:\n",
        "    pickle.dump(X_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with fs.open(base_dir+'X_test.pickle', 'wb') as handle:\n",
        "    pickle.dump(Val_test, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "PTlxRQfbx7ZD"
      },
      "id": "PTlxRQfbx7ZD",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cj6ZkPFTLAu",
        "outputId": "a36e123f-3b26-4b9a-e9f3-d2faec0bd792"
      },
      "id": "5cj6ZkPFTLAu",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.9/dist-packages (3.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.22.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from lightgbm) (0.40.0)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgbm"
      ],
      "metadata": {
        "id": "wPTIYqAaTaEw"
      },
      "id": "wPTIYqAaTaEw",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LGBM\n",
        "\n",
        "# Split data into train and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state = 42, stratify=y_train)\n",
        "\n",
        "# Get the train and test data for the training sequence\n",
        "train_data = lgbm.Dataset(X_train, label=y_train)\n",
        "test_data = lgbm.Dataset(X_test, label=y_test)\n"
      ],
      "metadata": {
        "id": "zMY9X_U_wHLR"
      },
      "id": "zMY9X_U_wHLR",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i9QuU9sWk0O",
        "outputId": "47052827-13b6-46aa-993c-42127db2b705"
      },
      "id": "7i9QuU9sWk0O",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([601, 447, 394, 303, 665])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters we'll use for the prediction\n",
        "parameters = {\n",
        "    # 'application': 'binary',\n",
        "    'objective': 'multiclass',\n",
        "    'metric': 'multi_logloss',\n",
        "    'boosting': 'gbdt',\n",
        "    # 'num_leaves': 31,\n",
        "    # 'feature_fraction': 0.5,\n",
        "    # 'bagging_fraction': 0.5,\n",
        "    # 'bagging_freq': 20,\n",
        "    # 'learning_rate': 0.05,\n",
        "    # 'verbose': 0,\n",
        "    # 'max_depth': 10,\n",
        "    # 'device': 'gpu',\n",
        "    'num_classes': len(id2label),\n",
        "    'min_data_in_leaf':300\n",
        "}\n",
        "\n",
        "# Train the classifier\n",
        "# model = lgbm.LGBMClassifier()\n",
        "# model = lgbm.LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.1, n_estimators=300, device = \"gpu\")\n",
        "classifier = lgbm.train(parameters,\n",
        "                       train_data,\n",
        "                       valid_sets=[train_data, test_data],\n",
        "                      #  num_boost_round=5000,\n",
        "                       early_stopping_rounds=10)\n",
        "\n",
        "\n",
        "# PREDICTION\n",
        "val_pred = classifier.predict(Val_test)\n",
        "\n",
        "# # Submission file\n",
        "# submission_df['target'] = val_pred.round().astype(int)\n",
        "# submission_df.to_csv('submission_lgbm.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "7seiu9bhSK_V",
        "outputId": "6bd33c46-e9f1-4926-d56e-6e9cfdfc2713"
      },
      "id": "7seiu9bhSK_V",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-35e617560ee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# 'max_depth': 10,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# 'device': 'gpu',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;34m'num_classes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;34m'min_data_in_leaf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m }\n",
            "\u001b[0;31mNameError\u001b[0m: name 'id2label' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M-OTHi43WTn2"
      },
      "id": "M-OTHi43WTn2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "tf-gpu.1-15.m93",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m93"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}